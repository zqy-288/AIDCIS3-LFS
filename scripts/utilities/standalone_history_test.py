#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„å†å²æ•°æ®åŠŸèƒ½æµ‹è¯•
ä¸ä¾èµ–ä¸»ç¨‹åºï¼Œé¿å…å†²çª
"""

import os
import csv
import json
from datetime import datetime
import sqlite3

def analyze_csv_data():
    """åˆ†æCSVæ•°æ®æ–‡ä»¶"""
    print("ğŸ“Š åˆ†æCSVå†å²æ•°æ®...")
    
    results = {}
    data_dirs = {
        "H00001": "Data/H00001/CCIDM",
        "H00002": "Data/H00002/CCIDM"
    }
    
    for hole_id, data_dir in data_dirs.items():
        results[hole_id] = {
            'directory_exists': False,
            'csv_files': [],
            'total_records': 0,
            'data_sample': [],
            'statistics': {}
        }
        
        if os.path.exists(data_dir):
            results[hole_id]['directory_exists'] = True
            print(f"  ğŸ“ {hole_id}: {data_dir}")
            
            # æŸ¥æ‰¾CSVæ–‡ä»¶
            csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
            results[hole_id]['csv_files'] = csv_files
            
            for csv_file in csv_files:
                csv_path = os.path.join(data_dir, csv_file)
                print(f"    ğŸ“„ å¤„ç†æ–‡ä»¶: {csv_file}")
                
                # å°è¯•è¯»å–CSVæ–‡ä»¶
                data_rows = []
                encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
                
                for encoding in encodings:
                    try:
                        with open(csv_path, 'r', encoding=encoding) as f:
                            reader = csv.reader(f)
                            data_rows = list(reader)
                        print(f"      âœ… æˆåŠŸè¯»å– {len(data_rows)} è¡Œ (ç¼–ç : {encoding})")
                        break
                    except UnicodeDecodeError:
                        continue
                    except Exception as e:
                        print(f"      âŒ è¯»å–å¤±è´¥ ({encoding}): {e}")
                        break
                
                if data_rows:
                    results[hole_id]['total_records'] += len(data_rows)
                    
                    # åˆ†ææ•°æ®ç»“æ„
                    if len(data_rows) > 1:
                        header = data_rows[0]
                        data_samples = data_rows[1:6]  # å‰5è¡Œæ•°æ®
                        
                        results[hole_id]['data_sample'] = {
                            'header': header,
                            'sample_rows': data_samples
                        }
                        
                        print(f"      ğŸ“‹ è¡¨å¤´: {header}")
                        print(f"      ğŸ“Š æ•°æ®æ ·æœ¬ (å‰5è¡Œ):")
                        for i, row in enumerate(data_samples):
                            print(f"        {i+1}. {row}")
                        
                        # ç»Ÿè®¡åˆ†æ
                        if len(data_rows) > 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è¿›è¡Œåˆ†æ
                            try:
                                # å‡è®¾æœ€åä¸€åˆ—æ˜¯ç›´å¾„æ•°æ®
                                diameters = []
                                for row in data_rows[1:]:  # è·³è¿‡è¡¨å¤´
                                    if len(row) > 0:
                                        try:
                                            # å°è¯•è§£ææœ€åä¸€åˆ—ä½œä¸ºç›´å¾„
                                            diameter = float(row[-1])
                                            diameters.append(diameter)
                                        except (ValueError, IndexError):
                                            continue
                                
                                if diameters:
                                    results[hole_id]['statistics'] = {
                                        'count': len(diameters),
                                        'min_diameter': min(diameters),
                                        'max_diameter': max(diameters),
                                        'avg_diameter': sum(diameters) / len(diameters),
                                        'diameter_range': max(diameters) - min(diameters)
                                    }
                                    
                                    stats = results[hole_id]['statistics']
                                    print(f"      ğŸ“ˆ ç»Ÿè®¡åˆ†æ:")
                                    print(f"        æ•°æ®ç‚¹æ•°: {stats['count']}")
                                    print(f"        ç›´å¾„èŒƒå›´: {stats['min_diameter']:.3f} - {stats['max_diameter']:.3f} mm")
                                    print(f"        å¹³å‡ç›´å¾„: {stats['avg_diameter']:.3f} mm")
                                    print(f"        ç›´å¾„å˜åŒ–: {stats['diameter_range']:.3f} mm")
                                    
                            except Exception as e:
                                print(f"      âš ï¸ ç»Ÿè®¡åˆ†æå¤±è´¥: {e}")
        else:
            print(f"  âŒ {hole_id}: ç›®å½•ä¸å­˜åœ¨ - {data_dir}")
    
    return results

def analyze_image_data():
    """åˆ†æå›¾åƒæ•°æ®"""
    print("ğŸ–¼ï¸ åˆ†æå›¾åƒå†å²æ•°æ®...")
    
    results = {}
    image_dirs = {
        "H00001": "Data/H00001/BISDM/result",
        "H00002": "Data/H00002/BISDM/result"
    }
    
    for hole_id, image_dir in image_dirs.items():
        results[hole_id] = {
            'directory_exists': False,
            'image_files': [],
            'image_count': 0,
            'file_sizes': {}
        }
        
        if os.path.exists(image_dir):
            results[hole_id]['directory_exists'] = True
            print(f"  ğŸ“ {hole_id}: {image_dir}")
            
            # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
            image_extensions = ['.png', '.jpg', '.jpeg', '.bmp']
            image_files = []
            
            for file in os.listdir(image_dir):
                if any(file.lower().endswith(ext) for ext in image_extensions):
                    image_files.append(file)
            
            image_files.sort()  # æ’åº
            results[hole_id]['image_files'] = image_files
            results[hole_id]['image_count'] = len(image_files)
            
            print(f"    ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ:")
            for i, img_file in enumerate(image_files):
                img_path = os.path.join(image_dir, img_file)
                try:
                    file_size = os.path.getsize(img_path)
                    results[hole_id]['file_sizes'][img_file] = file_size
                    print(f"      {i+1}. {img_file} ({file_size/1024:.1f} KB)")
                except Exception as e:
                    print(f"      {i+1}. {img_file} (å¤§å°è·å–å¤±è´¥: {e})")
        else:
            print(f"  âŒ {hole_id}: å›¾åƒç›®å½•ä¸å­˜åœ¨ - {image_dir}")
    
    return results

def check_database():
    """æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶"""
    print("ğŸ—„ï¸ æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶...")
    
    db_files = ['detection_system.db']
    results = {}
    
    for db_file in db_files:
        results[db_file] = {
            'exists': False,
            'size': 0,
            'tables': [],
            'record_counts': {}
        }
        
        if os.path.exists(db_file):
            results[db_file]['exists'] = True
            results[db_file]['size'] = os.path.getsize(db_file)
            
            print(f"  ğŸ“„ {db_file}: {results[db_file]['size']/1024:.1f} KB")
            
            try:
                # è¿æ¥æ•°æ®åº“å¹¶æŸ¥è¯¢è¡¨ä¿¡æ¯
                conn = sqlite3.connect(db_file)
                cursor = conn.cursor()
                
                # è·å–æ‰€æœ‰è¡¨å
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = [row[0] for row in cursor.fetchall()]
                results[db_file]['tables'] = tables
                
                print(f"    ğŸ“Š æ•°æ®è¡¨: {len(tables)}ä¸ª")
                
                # ç»Ÿè®¡æ¯ä¸ªè¡¨çš„è®°å½•æ•°
                for table in tables:
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table};")
                        count = cursor.fetchone()[0]
                        results[db_file]['record_counts'][table] = count
                        print(f"      {table}: {count}æ¡è®°å½•")
                    except Exception as e:
                        print(f"      {table}: æŸ¥è¯¢å¤±è´¥ ({e})")
                
                conn.close()
                
            except Exception as e:
                print(f"    âŒ æ•°æ®åº“è®¿é—®å¤±è´¥: {e}")
        else:
            print(f"  âŒ {db_file}: æ–‡ä»¶ä¸å­˜åœ¨")
    
    return results

def generate_summary_report(csv_results, image_results, db_results):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    print("ğŸ“‹ ç”Ÿæˆå†å²æ•°æ®åŠŸèƒ½æ±‡æ€»æŠ¥å‘Š...")
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'csv_analysis': csv_results,
        'image_analysis': image_results,
        'database_analysis': db_results,
        'summary': {
            'total_csv_files': 0,
            'total_csv_records': 0,
            'total_images': 0,
            'total_db_tables': 0,
            'total_db_records': 0
        }
    }
    
    # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
    for hole_data in csv_results.values():
        report['summary']['total_csv_files'] += len(hole_data.get('csv_files', []))
        report['summary']['total_csv_records'] += hole_data.get('total_records', 0)
    
    for hole_data in image_results.values():
        report['summary']['total_images'] += hole_data.get('image_count', 0)
    
    for db_data in db_results.values():
        report['summary']['total_db_tables'] += len(db_data.get('tables', []))
        for count in db_data.get('record_counts', {}).values():
            report['summary']['total_db_records'] += count
    
    # ä¿å­˜æŠ¥å‘Š
    report_filename = f"history_data_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    try:
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"  ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")
    except Exception as e:
        print(f"  âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AIDCIS å†å²æ•°æ®åŠŸèƒ½ç‹¬ç«‹åˆ†æ")
    print("=" * 60)
    print(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # 1. åˆ†æCSVæ•°æ®
    print("\n" + "="*60)
    csv_results = analyze_csv_data()
    
    # 2. åˆ†æå›¾åƒæ•°æ®
    print("\n" + "="*60)
    image_results = analyze_image_data()
    
    # 3. æ£€æŸ¥æ•°æ®åº“
    print("\n" + "="*60)
    db_results = check_database()
    
    # 4. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "="*60)
    report = generate_summary_report(csv_results, image_results, db_results)
    
    # 5. æ˜¾ç¤ºæœ€ç»ˆæ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ“Š å†å²æ•°æ®åŠŸèƒ½åˆ†ææ±‡æ€»:")
    print("-" * 40)
    
    summary = report['summary']
    print(f"ğŸ“„ CSVæ–‡ä»¶: {summary['total_csv_files']}ä¸ª")
    print(f"ğŸ“Š CSVè®°å½•: {summary['total_csv_records']}æ¡")
    print(f"ğŸ–¼ï¸ å›¾åƒæ–‡ä»¶: {summary['total_images']}å¼ ")
    print(f"ğŸ—„ï¸ æ•°æ®åº“è¡¨: {summary['total_db_tables']}ä¸ª")
    print(f"ğŸ“‹ æ•°æ®åº“è®°å½•: {summary['total_db_records']}æ¡")
    
    # åŠŸèƒ½çŠ¶æ€è¯„ä¼°
    print("\nğŸ¯ åŠŸèƒ½çŠ¶æ€è¯„ä¼°:")
    csv_ok = summary['total_csv_files'] > 0 and summary['total_csv_records'] > 0
    image_ok = summary['total_images'] > 0
    db_ok = summary['total_db_tables'] > 0
    
    print(f"  CSVæ•°æ®å¤„ç†: {'âœ… æ­£å¸¸' if csv_ok else 'âŒ å¼‚å¸¸'}")
    print(f"  å›¾åƒæ•°æ®ç®¡ç†: {'âœ… æ­£å¸¸' if image_ok else 'âŒ å¼‚å¸¸'}")
    print(f"  æ•°æ®åº“åŠŸèƒ½: {'âœ… æ­£å¸¸' if db_ok else 'âŒ å¼‚å¸¸'}")
    
    if csv_ok and image_ok:
        print("\nğŸ‰ å†å²æ•°æ®åŠŸèƒ½åˆ†æå®Œæˆï¼")
        print("ğŸ’¡ ä¸»è¦åŠŸèƒ½ç»„ä»¶éƒ½å·²å°±ç»ªå¹¶åŒ…å«æ•°æ®")
        print("ğŸ”§ ç³»ç»Ÿå…·å¤‡å®Œæ•´çš„å†å²æ•°æ®å¤„ç†èƒ½åŠ›")
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½ç»„ä»¶éœ€è¦æ£€æŸ¥")
    
    return 0

if __name__ == "__main__":
    try:
        exit_code = main()
        exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        exit(1)
    except Exception as e:
        print(f"\n\nğŸ’¥ åˆ†æè¿‡ç¨‹å‡ºç°å¼‚å¸¸: {e}")
        exit(1)
