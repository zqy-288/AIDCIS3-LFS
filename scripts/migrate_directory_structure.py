#!/usr/bin/env python3
"""
AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
ç›®å½•è¿ç§»å·¥å…· - å°†Hæ ¼å¼ç›®å½•ç»“æ„è¿ç§»ä¸ºæ–°æ ¼å¼C{col:03d}R{row:03d}
æ”¯æŒå®‰å…¨çš„ç›®å½•é‡å‘½åå’Œæ•°æ®å®Œæ•´æ€§éªŒè¯
AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
"""

import os
import shutil
import json
import re
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import argparse

class DirectoryMigrationTool:
    """ç›®å½•ç»“æ„è¿ç§»å·¥å…·"""
    
    def __init__(self, base_data_path: str = "Data", archive_path: str = "Archive", backup_path: str = "Backup"):
        """
        åˆå§‹åŒ–è¿ç§»å·¥å…·
        
        Args:
            base_data_path: æ•°æ®åŸºç¡€è·¯å¾„
            archive_path: å½’æ¡£è·¯å¾„
            backup_path: å¤‡ä»½è·¯å¾„
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        self.base_data_path = Path(base_data_path)
        self.archive_path = Path(archive_path)
        self.backup_path = Path(backup_path)
        
        # ç¡®ä¿è·¯å¾„å­˜åœ¨
        self.base_data_path.mkdir(exist_ok=True)
        if self.archive_path.exists():
            self.archive_path.mkdir(exist_ok=True)
        self.backup_path.mkdir(exist_ok=True)
        
        # è¿ç§»è®°å½•
        self.migration_log: List[Dict] = []
        self.errors: List[str] = []
        
        # æ”¯æŒçš„æ ¼å¼è½¬æ¢
        self.format_patterns = {
            'H_format': r'^H(\d+)$',  # H00001 æ ¼å¼
            'coord_format': r'^\((\d+),(\d+)\)$',  # (1,2) æ ¼å¼
            'rc_format': r'^R(\d+)C(\d+)$',  # R001C002 æ ¼å¼
            'new_format': r'^C(\d{3})R(\d{3})$'  # C001R002 æ ¼å¼
        }
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def validate_new_format(self, hole_id: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæ–°æ ¼å¼ID"""
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        pattern = r'^C\d{3}R\d{3}$'
        return bool(re.match(pattern, hole_id))
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def parse_hole_coordinates(self, hole_id: str) -> Optional[Tuple[int, int]]:
        """
        è§£æå­”ä½IDè·å–è¡Œåˆ—åæ ‡
        
        Args:
            hole_id: å­”ä½ID
            
        Returns:
            Optional[Tuple[int, int]]: (row, column) æˆ– None
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        # æ–°æ ¼å¼: C001R002 -> (row=2, col=1)
        new_match = re.match(r'^C(\d{3})R(\d{3})$', hole_id)
        if new_match:
            col, row = map(int, new_match.groups())
            return (row, col)
        
        # åæ ‡æ ¼å¼: (1,2) -> (row=1, col=2)
        coord_match = re.match(r'^\((\d+),(\d+)\)$', hole_id)
        if coord_match:
            row, col = map(int, coord_match.groups())
            return (row, col)
        
        # R###C###æ ¼å¼: R001C002 -> (row=1, col=2)
        rc_match = re.match(r'^R(\d+)C(\d+)$', hole_id)
        if rc_match:
            row, col = map(int, rc_match.groups())
            return (row, col)
        
        # Hæ ¼å¼æ— æ³•ç›´æ¥è½¬æ¢
        return None
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def convert_to_new_format(self, hole_id: str, row: Optional[int] = None, col: Optional[int] = None) -> str:
        """
        è½¬æ¢ä¸ºæ–°æ ¼å¼ID
        
        Args:
            hole_id: åŸå§‹å­”ä½ID
            row: å¯é€‰çš„è¡Œå·
            col: å¯é€‰çš„åˆ—å·
            
        Returns:
            str: æ–°æ ¼å¼ID
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if self.validate_new_format(hole_id):
            return hole_id
        
        # å°è¯•ä»hole_idè§£æåæ ‡
        coords = self.parse_hole_coordinates(hole_id)
        if coords:
            row, col = coords
            return f"C{col:03d}R{row:03d}"
        
        # å¦‚æœæä¾›äº†å¤–éƒ¨åæ ‡ä¿¡æ¯
        if row is not None and col is not None:
            return f"C{col:03d}R{row:03d}"
        
        # æ— æ³•è½¬æ¢ï¼Œè¿”å›åŸID
        return hole_id
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def scan_directories(self, path: Path) -> List[Tuple[Path, str]]:
        """
        æ‰«æç›®å½•ï¼Œæ‰¾åˆ°éœ€è¦è¿ç§»çš„ç›®å½•
        
        Args:
            path: æ‰«æè·¯å¾„
            
        Returns:
            List[Tuple[Path, str]]: [(ç›®å½•è·¯å¾„, å­”ä½ID)]
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        directories_to_migrate = []
        
        if not path.exists():
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: {path}")
            return directories_to_migrate
        
        print(f"ğŸ” æ‰«æç›®å½•: {path}")
        
        for item in path.iterdir():
            if item.is_dir():
                dir_name = item.name
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»ï¼ˆéæ–°æ ¼å¼çš„ç›®å½•ï¼‰
                if not self.validate_new_format(dir_name):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¯è¯†åˆ«çš„æ—§æ ¼å¼
                    if (re.match(r'^H\d+$', dir_name) or  # Hæ ¼å¼
                        re.match(r'^\(\d+,\d+\)$', dir_name) or  # åæ ‡æ ¼å¼
                        re.match(r'^R\d+C\d+$', dir_name)):  # RCæ ¼å¼
                        
                        directories_to_migrate.append((item, dir_name))
                        print(f"ğŸ“ å‘ç°éœ€è¿ç§»ç›®å½•: {dir_name}")
        
        print(f"âœ… æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(directories_to_migrate)} ä¸ªç›®å½•éœ€è¦è¿ç§»")
        return directories_to_migrate
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def create_backup(self, source_path: Path, backup_name: str) -> Path:
        """
        åˆ›å»ºå¤‡ä»½
        
        Args:
            source_path: æºè·¯å¾„
            backup_name: å¤‡ä»½åç§°
            
        Returns:
            Path: å¤‡ä»½è·¯å¾„
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.backup_path / f"{backup_name}_{timestamp}"
        
        try:
            print(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½: {source_path} -> {backup_dir}")
            shutil.copytree(source_path, backup_dir)
            
            # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
            metadata = {
                'source_path': str(source_path),
                'backup_path': str(backup_dir),
                'created_at': timestamp,
                'backup_type': 'pre_migration'
            }
            
            metadata_file = backup_dir / "backup_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_dir}")
            return backup_dir
            
        except Exception as e:
            error_msg = f"âŒ åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}"
            print(error_msg)
            self.errors.append(error_msg)
            raise
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def migrate_single_directory(self, source_dir: Path, old_hole_id: str, dry_run: bool = False) -> bool:
        """
        è¿ç§»å•ä¸ªç›®å½•
        
        Args:
            source_dir: æºç›®å½•è·¯å¾„
            old_hole_id: æ—§å­”ä½ID
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        try:
            # å°è¯•è½¬æ¢ä¸ºæ–°æ ¼å¼
            new_hole_id = self.convert_to_new_format(old_hole_id)
            
            # å¦‚æœæ— æ³•è½¬æ¢ï¼Œè·³è¿‡
            if new_hole_id == old_hole_id and not self.validate_new_format(old_hole_id):
                warning_msg = f"âš ï¸ æ— æ³•è½¬æ¢å­”ä½ID: {old_hole_id}"
                print(warning_msg)
                self.errors.append(warning_msg)
                return False
            
            # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼ï¼Œè·³è¿‡
            if old_hole_id == new_hole_id:
                print(f"â„¹ï¸ å·²æ˜¯æ–°æ ¼å¼ï¼Œè·³è¿‡: {old_hole_id}")
                return True
            
            # ç¡®å®šæ–°ç›®å½•è·¯å¾„
            new_dir = source_dir.parent / new_hole_id
            
            # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å·²å­˜åœ¨
            if new_dir.exists() and new_dir != source_dir:
                error_msg = f"âŒ ç›®æ ‡ç›®å½•å·²å­˜åœ¨: {new_dir}"
                print(error_msg)
                self.errors.append(error_msg)
                return False
            
            migration_record = {
                'old_hole_id': old_hole_id,
                'new_hole_id': new_hole_id,
                'source_path': str(source_dir),
                'target_path': str(new_dir),
                'timestamp': datetime.now().isoformat(),
                'dry_run': dry_run
            }
            
            if dry_run:
                print(f"ğŸ”„ [æ¨¡æ‹Ÿ] è¿ç§»: {old_hole_id} -> {new_hole_id}")
                print(f"     æºè·¯å¾„: {source_dir}")
                print(f"     ç›®æ ‡è·¯å¾„: {new_dir}")
                migration_record['status'] = 'simulated'
            else:
                print(f"ğŸ”„ è¿ç§»ç›®å½•: {old_hole_id} -> {new_hole_id}")
                
                # é‡å‘½åç›®å½•
                source_dir.rename(new_dir)
                
                print(f"âœ… è¿ç§»æˆåŠŸ: {source_dir} -> {new_dir}")
                migration_record['status'] = 'completed'
            
            self.migration_log.append(migration_record)
            return True
            
        except Exception as e:
            error_msg = f"âŒ è¿ç§»å¤±è´¥ {old_hole_id}: {e}"
            print(error_msg)
            self.errors.append(error_msg)
            
            migration_record = {
                'old_hole_id': old_hole_id,
                'source_path': str(source_dir),
                'timestamp': datetime.now().isoformat(),
                'status': 'failed',
                'error': str(e),
                'dry_run': dry_run
            }
            self.migration_log.append(migration_record)
            return False
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def migrate_data_directories(self, dry_run: bool = False, create_backup: bool = True) -> bool:
        """
        è¿ç§»æ•°æ®ç›®å½•
        
        Args:
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        print(f"ğŸš€ å¼€å§‹è¿ç§»æ•°æ®ç›®å½•: {self.base_data_path}")
        print(f"   æ¨¡å¼: {'æ¨¡æ‹Ÿè¿è¡Œ' if dry_run else 'å®é™…æ‰§è¡Œ'}")
        print(f"   å¤‡ä»½: {'æ˜¯' if create_backup else 'å¦'}")
        
        # åˆ›å»ºå¤‡ä»½
        if create_backup and not dry_run:
            try:
                self.create_backup(self.base_data_path, "data_directories")
            except Exception as e:
                print(f"âŒ å¤‡ä»½å¤±è´¥ï¼Œåœæ­¢è¿ç§»: {e}")
                return False
        
        # æ‰«æéœ€è¦è¿ç§»çš„ç›®å½•
        directories_to_migrate = self.scan_directories(self.base_data_path)
        
        if not directories_to_migrate:
            print("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„ç›®å½•")
            return True
        
        # æ‰§è¡Œè¿ç§»
        success_count = 0
        for dir_path, hole_id in directories_to_migrate:
            if self.migrate_single_directory(dir_path, hole_id, dry_run):
                success_count += 1
        
        print(f"\nğŸ“Š æ•°æ®ç›®å½•è¿ç§»å®Œæˆ:")
        print(f"   æ€»è®¡: {len(directories_to_migrate)} ä¸ªç›®å½•")
        print(f"   æˆåŠŸ: {success_count} ä¸ª")
        print(f"   å¤±è´¥: {len(directories_to_migrate) - success_count} ä¸ª")
        
        return success_count == len(directories_to_migrate)
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def migrate_archive_directories(self, dry_run: bool = False, create_backup: bool = True) -> bool:
        """
        è¿ç§»å½’æ¡£ç›®å½•
        
        Args:
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        if not self.archive_path.exists():
            print(f"â„¹ï¸ å½’æ¡£è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {self.archive_path}")
            return True
        
        print(f"ğŸ—ƒï¸ å¼€å§‹è¿ç§»å½’æ¡£ç›®å½•: {self.archive_path}")
        
        # åˆ›å»ºå¤‡ä»½
        if create_backup and not dry_run:
            try:
                self.create_backup(self.archive_path, "archive_directories")
            except Exception as e:
                print(f"âŒ å¤‡ä»½å¤±è´¥ï¼Œåœæ­¢è¿ç§»: {e}")
                return False
        
        # æ‰«æéœ€è¦è¿ç§»çš„ç›®å½•
        directories_to_migrate = self.scan_directories(self.archive_path)
        
        if not directories_to_migrate:
            print("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„å½’æ¡£ç›®å½•")
            return True
        
        # æ‰§è¡Œè¿ç§»
        success_count = 0
        for dir_path, hole_id in directories_to_migrate:
            if self.migrate_single_directory(dir_path, hole_id, dry_run):
                success_count += 1
        
        print(f"\nğŸ“Š å½’æ¡£ç›®å½•è¿ç§»å®Œæˆ:")
        print(f"   æ€»è®¡: {len(directories_to_migrate)} ä¸ªç›®å½•")
        print(f"   æˆåŠŸ: {success_count} ä¸ª")
        print(f"   å¤±è´¥: {len(directories_to_migrate) - success_count} ä¸ª")
        
        return success_count == len(directories_to_migrate)
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def generate_migration_report(self, output_file: str = "migration_report.json") -> bool:
        """
        ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        try:
            report = {
                'migration_summary': {
                    'total_directories': len(self.migration_log),
                    'successful_migrations': len([r for r in self.migration_log if r.get('status') == 'completed']),
                    'failed_migrations': len([r for r in self.migration_log if r.get('status') == 'failed']),
                    'simulated_migrations': len([r for r in self.migration_log if r.get('status') == 'simulated']),
                    'errors_count': len(self.errors),
                    'generated_at': datetime.now().isoformat()
                },
                'migration_log': self.migration_log,
                'errors': self.errors,
                'format_conversion_rules': {
                    'target_format': 'C{col:03d}R{row:03d}',
                    'supported_source_formats': [
                        'H{number} (éœ€è¦é¢å¤–åæ ‡ä¿¡æ¯)',
                        '(row,col) åæ ‡æ ¼å¼',
                        'R{row}C{col} æ ¼å¼'
                    ]
                }
            }
            
            output_path = Path(output_file)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ è¿ç§»æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return True
            
        except Exception as e:
            error_msg = f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}"
            print(error_msg)
            self.errors.append(error_msg)
            return False
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ
    
    def run_full_migration(self, dry_run: bool = False, create_backup: bool = True) -> bool:
        """
        æ‰§è¡Œå®Œæ•´è¿ç§»
        
        Args:
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
        print("=" * 60)
        print("ğŸ”„ AIDCIS ç›®å½•ç»“æ„è¿ç§»å·¥å…·")
        print("=" * 60)
        print(f"ç›®æ ‡æ ¼å¼: C{{col:03d}}R{{row:03d}}")
        print(f"æ¨¡å¼: {'æ¨¡æ‹Ÿè¿è¡Œ' if dry_run else 'å®é™…æ‰§è¡Œ'}")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        # æ‰§è¡Œæ•°æ®ç›®å½•è¿ç§»
        data_success = self.migrate_data_directories(dry_run, create_backup)
        
        # æ‰§è¡Œå½’æ¡£ç›®å½•è¿ç§»
        archive_success = self.migrate_archive_directories(dry_run, create_backup)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = f"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        self.generate_migration_report(report_file)
        
        # è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š è¿ç§»æ€»ç»“")
        print("=" * 60)
        print(f"æ•°æ®ç›®å½•è¿ç§»: {'âœ… æˆåŠŸ' if data_success else 'âŒ å¤±è´¥'}")
        print(f"å½’æ¡£ç›®å½•è¿ç§»: {'âœ… æˆåŠŸ' if archive_success else 'âŒ å¤±è´¥'}")
        print(f"æ€»è®¡è¿ç§»: {len(self.migration_log)} ä¸ªç›®å½•")
        print(f"é”™è¯¯æ•°é‡: {len(self.errors)}")
        
        if self.errors:
            print("\nâŒ é”™è¯¯åˆ—è¡¨:")
            for error in self.errors:
                print(f"  - {error}")
        
        overall_success = data_success and archive_success
        print(f"\nğŸ¯ æ•´ä½“çŠ¶æ€: {'âœ… æˆåŠŸ' if overall_success else 'âŒ å¤±è´¥'}")
        print("=" * 60)
        
        return overall_success
        # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ


def main():
    """ä¸»å‡½æ•°"""
    # AIå‘˜å·¥3å·ä¿®æ”¹å¼€å§‹
    parser = argparse.ArgumentParser(description="AIDCIS ç›®å½•ç»“æ„è¿ç§»å·¥å…·")
    parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ‰§è¡Œè¿ç§»")
    parser.add_argument("--no-backup", action="store_true", help="ä¸åˆ›å»ºå¤‡ä»½")
    parser.add_argument("--data-path", default="Data", help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--archive-path", default="Archive", help="å½’æ¡£ç›®å½•è·¯å¾„")
    parser.add_argument("--backup-path", default="Backup", help="å¤‡ä»½ç›®å½•è·¯å¾„")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¿ç§»å·¥å…·å®ä¾‹
    migration_tool = DirectoryMigrationTool(
        base_data_path=args.data_path,
        archive_path=args.archive_path,
        backup_path=args.backup_path
    )
    
    # æ‰§è¡Œè¿ç§»
    success = migration_tool.run_full_migration(
        dry_run=args.dry_run,
        create_backup=not args.no_backup
    )
    
    # é€€å‡ºçŠ¶æ€
    exit(0 if success else 1)
    # AIå‘˜å·¥3å·ä¿®æ”¹ç»“æŸ


if __name__ == "__main__":
    main()