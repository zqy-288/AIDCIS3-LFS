#!/usr/bin/env python3
"""
å­”ä½IDæ ¼å¼è½¬æ¢å‰çš„æ•°æ®å¤‡ä»½è„šæœ¬
AIå‘˜å·¥1å·åˆ›å»º - 2025-01-14

åŠŸèƒ½ï¼š
- å¤‡ä»½æ‰€æœ‰å¯èƒ½åŒ…å«å­”ä½IDçš„å…³é”®æ–‡ä»¶
- åˆ›å»ºæ—¶é—´æˆ³ç›®å½•ä¿å­˜å¤‡ä»½
- ç”Ÿæˆå¤‡ä»½æ¸…å•å’ŒéªŒè¯æ–‡ä»¶
"""

import os
import shutil
import json
import hashlib
import datetime
from pathlib import Path
from typing import List, Dict, Any


class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.backup_dir = self.project_root / "backups" / f"hole_id_conversion_backup_{self.timestamp}"
        self.backup_manifest = {
            "backup_time": datetime.datetime.now().isoformat(),
            "backup_purpose": "Hole ID format conversion preparation",
            "project_root": str(self.project_root),
            "files": [],
            "directories": [],
            "checksums": {}
        }
    
    def create_backup_structure(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•ç»“æ„"""
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºå¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def calculate_checksum(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶çš„MD5æ ¡éªŒå’Œ"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è®¡ç®—æ ¡éªŒå’Œ {file_path}: {e}")
            return ""
    
    def backup_file(self, source_path: Path, relative_path: str):
        """å¤‡ä»½å•ä¸ªæ–‡ä»¶"""
        if not source_path.exists():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
            return
        
        backup_file_path = self.backup_dir / relative_path
        backup_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            shutil.copy2(source_path, backup_file_path)
            checksum = self.calculate_checksum(source_path)
            
            self.backup_manifest["files"].append({
                "original_path": str(source_path),
                "backup_path": str(backup_file_path),
                "relative_path": relative_path,
                "size": source_path.stat().st_size,
                "modified_time": datetime.datetime.fromtimestamp(source_path.stat().st_mtime).isoformat()
            })
            
            if checksum:
                self.backup_manifest["checksums"][str(source_path)] = checksum
            
            print(f"âœ… å¤‡ä»½æ–‡ä»¶: {relative_path}")
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥ {source_path}: {e}")
    
    def backup_directory(self, source_path: Path, relative_path: str):
        """å¤‡ä»½æ•´ä¸ªç›®å½•"""
        if not source_path.exists() or not source_path.is_dir():
            print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {source_path}")
            return
        
        backup_dir_path = self.backup_dir / relative_path
        
        try:
            shutil.copytree(source_path, backup_dir_path, dirs_exist_ok=True)
            
            self.backup_manifest["directories"].append({
                "original_path": str(source_path),
                "backup_path": str(backup_dir_path),
                "relative_path": relative_path
            })
            
            print(f"âœ… å¤‡ä»½ç›®å½•: {relative_path}")
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½ç›®å½•å¤±è´¥ {source_path}: {e}")
    
    def backup_core_files(self):
        """å¤‡ä»½æ ¸å¿ƒä»£ç æ–‡ä»¶"""
        print("\nğŸ“ å¤‡ä»½æ ¸å¿ƒä»£ç æ–‡ä»¶...")
        
        core_files = [
            # æ ¸å¿ƒæ•°æ®æ¨¡å‹
            "src/aidcis2/models/hole_data.py",
            "src/aidcis2/dxf_parser.py",
            "src/models/batch_data_manager.py",
            
            # ä¸»è¦æ•°æ®æ–‡ä»¶
            "assets/dxf/DXF Graph/dongzhong_hole_grid.json",
            "reports/test_report_WP-2025-001.json",
            
            # ä¸šåŠ¡é€»è¾‘å±‚
            "src/modules/report_output_interface.py",
            "src/modules/realtime_chart.py",
            "src/main_window.py",
            "src/modules/archive_manager.py",
            
            # UIæ˜¾ç¤ºå±‚
            "src/aidcis2/graphics/hole_item.py",
            "src/aidcis2/graphics/dynamic_sector_view.py",
            "src/aidcis2/graphics/graphics_view.py",
            "src/aidcis2/graphics/sector_view.py",
            
            # å·¥å…·è„šæœ¬
            "parse_dongzhong_dxf.py"
        ]
        
        for file_path in core_files:
            source_path = self.project_root / file_path
            self.backup_file(source_path, file_path)
    
    def backup_data_directories(self):
        """å¤‡ä»½æ•°æ®ç›®å½•"""
        print("\nğŸ“ å¤‡ä»½æ•°æ®ç›®å½•...")
        
        data_dirs = [
            "Data/C001R001",
            "Data/C002R001", 
            "Data/C003R001",
            "assets/archive/Archive/C001R001",
            "src/data"
        ]
        
        for dir_path in data_dirs:
            source_path = self.project_root / dir_path
            if source_path.exists():
                self.backup_directory(source_path, dir_path)
    
    def backup_batch_data_files(self):
        """å¤‡ä»½æ‰¹å¤„ç†æ•°æ®æ–‡ä»¶"""
        print("\nğŸ“ å¤‡ä»½æ‰¹å¤„ç†æ•°æ®æ–‡ä»¶...")
        
        src_data_dir = self.project_root / "src" / "data"
        if src_data_dir.exists():
            for file_path in src_data_dir.glob("batch_*.json"):
                relative_path = f"src/data/{file_path.name}"
                self.backup_file(file_path, relative_path)
    
    def save_manifest(self):
        """ä¿å­˜å¤‡ä»½æ¸…å•"""
        manifest_path = self.backup_dir / "backup_manifest.json"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        self.backup_manifest["statistics"] = {
            "total_files": len(self.backup_manifest["files"]),
            "total_directories": len(self.backup_manifest["directories"]),
            "total_checksums": len(self.backup_manifest["checksums"])
        }
        
        try:
            with open(manifest_path, 'w', encoding='utf-8') as f:
                json.dump(self.backup_manifest, f, indent=2, ensure_ascii=False)
            print(f"âœ… ä¿å­˜å¤‡ä»½æ¸…å•: {manifest_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤‡ä»½æ¸…å•å¤±è´¥: {e}")
    
    def create_restore_script(self):
        """åˆ›å»ºæ¢å¤è„šæœ¬"""
        restore_script_path = self.backup_dir / "restore_backup.py"
        
        restore_script_content = f'''#!/usr/bin/env python3
"""
å­”ä½IDæ ¼å¼è½¬æ¢å¤‡ä»½æ¢å¤è„šæœ¬
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().isoformat()}
"""

import os
import shutil
import json
from pathlib import Path

def restore_backup():
    """æ¢å¤å¤‡ä»½"""
    backup_dir = Path(__file__).parent
    project_root = Path("{self.project_root}")
    
    print("âš ï¸ è­¦å‘Š: æ­¤æ“ä½œå°†è¦†ç›–ç°æœ‰æ–‡ä»¶!")
    confirm = input("æ˜¯å¦ç»§ç»­æ¢å¤å¤‡ä»½? (y/N): ")
    if confirm.lower() != 'y':
        print("âŒ æ¢å¤æ“ä½œå·²å–æ¶ˆ")
        return
    
    # è¯»å–å¤‡ä»½æ¸…å•
    manifest_path = backup_dir / "backup_manifest.json"
    with open(manifest_path, 'r', encoding='utf-8') as f:
        manifest = json.load(f)
    
    # æ¢å¤æ–‡ä»¶
    for file_info in manifest["files"]:
        backup_path = Path(file_info["backup_path"])
        original_path = Path(file_info["original_path"])
        
        if backup_path.exists():
            original_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(backup_path, original_path)
            print(f"âœ… æ¢å¤æ–‡ä»¶: {{original_path}}")
        else:
            print(f"âš ï¸ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {{backup_path}}")
    
    # æ¢å¤ç›®å½•
    for dir_info in manifest["directories"]:
        backup_path = Path(dir_info["backup_path"])
        original_path = Path(dir_info["original_path"])
        
        if backup_path.exists():
            if original_path.exists():
                shutil.rmtree(original_path)
            shutil.copytree(backup_path, original_path)
            print(f"âœ… æ¢å¤ç›®å½•: {{original_path}}")
        else:
            print(f"âš ï¸ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: {{backup_path}}")
    
    print("âœ… å¤‡ä»½æ¢å¤å®Œæˆ!")

if __name__ == "__main__":
    restore_backup()
'''
        
        try:
            with open(restore_script_path, 'w', encoding='utf-8') as f:
                f.write(restore_script_content)
            
            # è®¾ç½®æ‰§è¡Œæƒé™
            os.chmod(restore_script_path, 0o755)
            print(f"âœ… åˆ›å»ºæ¢å¤è„šæœ¬: {restore_script_path}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ¢å¤è„šæœ¬å¤±è´¥: {e}")
    
    def run_backup(self):
        """æ‰§è¡Œå®Œæ•´å¤‡ä»½"""
        print(f"ğŸš€ å¼€å§‹å­”ä½IDæ ¼å¼è½¬æ¢å‰å¤‡ä»½...")
        print(f"ğŸ“… å¤‡ä»½æ—¶é—´: {self.backup_manifest['backup_time']}")
        print(f"ğŸ“ å¤‡ä»½ç›®å½•: {self.backup_dir}")
        
        self.create_backup_structure()
        self.backup_core_files()
        self.backup_data_directories()
        self.backup_batch_data_files()
        self.save_manifest()
        self.create_restore_script()
        
        print(f"\nâœ… å¤‡ä»½å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ–‡ä»¶æ•°é‡: {len(self.backup_manifest['files'])}")
        print(f"   - ç›®å½•æ•°é‡: {len(self.backup_manifest['directories'])}")
        print(f"   - æ ¡éªŒå’Œæ•°é‡: {len(self.backup_manifest['checksums'])}")
        print(f"ğŸ“ å¤‡ä»½ä½ç½®: {self.backup_dir}")
        print(f"ğŸ“„ æ¸…å•æ–‡ä»¶: {self.backup_dir}/backup_manifest.json")
        print(f"ğŸ”§ æ¢å¤è„šæœ¬: {self.backup_dir}/restore_backup.py")


def main():
    """ä¸»å‡½æ•°"""
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    print("ğŸ›¡ï¸ å­”ä½IDæ ¼å¼è½¬æ¢å‰æ•°æ®å¤‡ä»½å·¥å…·")
    print("=" * 50)
    
    backup_manager = BackupManager(str(project_root))
    backup_manager.run_backup()


if __name__ == "__main__":
    main()