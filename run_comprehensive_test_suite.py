#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•å¥—ä»¶è¿è¡Œå™¨ - é›¶å®¹å¿å…¨é¢æµ‹è¯•
Comprehensive test suite runner with zero tolerance
åŒ…å«: å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯• + UIè‡ªåŠ¨åŒ–æµ‹è¯• + æ€§èƒ½æµ‹è¯•
"""

import sys
import os
import time
import subprocess
import logging
from pathlib import Path
from typing import Dict, Any, List
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(PROJECT_ROOT / 'comprehensive_test_log.txt'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class ComprehensiveTestSuite:
    """ç»¼åˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = time.time()
        self.test_stats = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'skipped_tests': 0,
            'execution_time': 0
        }
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•å¥—ä»¶"""
        logger.info("ğŸš€ å¼€å§‹ç»¼åˆæµ‹è¯•å¥—ä»¶ - é›¶å®¹å¿æµ‹è¯•")
        logger.info("=" * 60)
        
        # æµ‹è¯•å¥—ä»¶é…ç½®
        test_suites = [
            {
                'name': 'é›¶å®¹å¿æ ¸å¿ƒæµ‹è¯•',
                'script': 'test_runner_zero_tolerance_fixed.py',
                'critical': True,
                'timeout': 120
            },
            {
                'name': 'UIè‡ªåŠ¨åŒ–æµ‹è¯•',
                'script': 'tests/playwright/test_comprehensive_ui_automation.py',
                'critical': True,
                'timeout': 300,
                'use_pytest': True
            },
            {
                'name': 'ä¸»çª—å£åˆå§‹åŒ–æµ‹è¯•',
                'script': 'tests/playwright/test_main_window_initialization.py',
                'critical': True,
                'timeout': 180,
                'use_pytest': True
            },
            {
                'name': 'DXFåŠŸèƒ½æµ‹è¯•',
                'script': 'tests/playwright/test_dxf_loading_functionality.py',
                'critical': False,
                'timeout': 240,
                'use_pytest': True
            }
        ]
        
        # æ‰§è¡Œæµ‹è¯•å¥—ä»¶
        for suite in test_suites:
            logger.info(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•å¥—ä»¶: {suite['name']}")
            result = self.run_test_suite(suite)
            self.test_results[suite['name']] = result
            
            # å…³é”®æµ‹è¯•å¤±è´¥åˆ™åœæ­¢
            if suite['critical'] and not result['passed']:
                logger.error(f"âŒ å…³é”®æµ‹è¯•å¥—ä»¶å¤±è´¥: {suite['name']}")
                logger.error("ğŸ›‘ åœæ­¢æ‰§è¡Œåç»­æµ‹è¯•")
                break
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        # è¿”å›æ€»ä½“ç»“æœ
        return self.calculate_overall_success()
    
    def run_test_suite(self, suite_config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•å¥—ä»¶"""
        result = {
            'name': suite_config['name'],
            'passed': False,
            'output': '',
            'error': '',
            'execution_time': 0,
            'test_count': 0,
            'passed_count': 0,
            'failed_count': 0
        }
        
        start_time = time.time()
        
        try:
            # æ„å»ºå‘½ä»¤
            if suite_config.get('use_pytest', False):
                cmd = [
                    sys.executable, '-m', 'pytest',
                    suite_config['script'],
                    '-v', '--tb=short',
                    '--disable-warnings'
                ]
            else:
                cmd = [sys.executable, suite_config['script']]
            
            logger.info(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # è¿è¡Œæµ‹è¯•
            process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=suite_config.get('timeout', 300),
                cwd=PROJECT_ROOT
            )
            
            result['execution_time'] = time.time() - start_time
            result['output'] = process.stdout
            result['error'] = process.stderr
            
            # åˆ†ææµ‹è¯•ç»“æœ
            if process.returncode == 0:
                result['passed'] = True
                logger.info(f"âœ… {suite_config['name']} - é€šè¿‡")
            else:
                result['passed'] = False
                logger.error(f"âŒ {suite_config['name']} - å¤±è´¥ (è¿”å›ç : {process.returncode})")
            
            # è§£ææµ‹è¯•ç»Ÿè®¡
            self.parse_test_statistics(result)
            
        except subprocess.TimeoutExpired:
            result['error'] = f"æµ‹è¯•è¶…æ—¶ ({suite_config.get('timeout', 300)}ç§’)"
            result['execution_time'] = suite_config.get('timeout', 300)
            logger.error(f"â° {suite_config['name']} - è¶…æ—¶")
            
        except Exception as e:
            result['error'] = f"æ‰§è¡Œå¼‚å¸¸: {e}"
            result['execution_time'] = time.time() - start_time
            logger.error(f"ğŸ’¥ {suite_config['name']} - å¼‚å¸¸: {e}")
        
        return result
    
    def parse_test_statistics(self, result: Dict[str, Any]):
        """è§£ææµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
        output = result['output'] + result['error']
        
        # æŸ¥æ‰¾pytestæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        import re
        
        # pytestæ ¼å¼: "5 passed" æˆ– "3 failed, 2 passed"
        pytest_pattern = r'(\d+)\s+(passed|failed|skipped)'
        matches = re.findall(pytest_pattern, output, re.IGNORECASE)
        
        for count, status in matches:
            count = int(count)
            if status.lower() == 'passed':
                result['passed_count'] = count
            elif status.lower() == 'failed':
                result['failed_count'] = count
            elif status.lower() == 'skipped':
                result['skipped_count'] = count
        
        result['test_count'] = result['passed_count'] + result['failed_count'] + result.get('skipped_count', 0)
        
        # æŸ¥æ‰¾è‡ªå®šä¹‰æµ‹è¯•æ ¼å¼ "é€šè¿‡: X/Y"
        custom_pattern = r'é€šè¿‡:\s*(\d+)\/(\d+)'
        custom_match = re.search(custom_pattern, output)
        if custom_match:
            result['passed_count'] = int(custom_match.group(1))
            result['test_count'] = int(custom_match.group(2))
            result['failed_count'] = result['test_count'] - result['passed_count']
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.test_stats['total_tests'] += result['test_count']
        self.test_stats['passed_tests'] += result['passed_count']
        self.test_stats['failed_tests'] += result['failed_count']
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š...")
        
        total_execution_time = time.time() - self.start_time
        self.test_stats['execution_time'] = total_execution_time
        
        # è®¡ç®—æˆåŠŸç‡
        success_rate = 0
        if self.test_stats['total_tests'] > 0:
            success_rate = (self.test_stats['passed_tests'] / self.test_stats['total_tests']) * 100
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_content = f"""# ğŸ¯ AIDCIS3-LFS ç»¼åˆæµ‹è¯•æŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}  
**æ€»æ‰§è¡Œæ—¶é—´**: {total_execution_time:.2f} ç§’  
**æµ‹è¯•æˆåŠŸç‡**: {success_rate:.1f}%

## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°é‡ |
|------|------|
| æ€»æµ‹è¯•æ•° | {self.test_stats['total_tests']} |
| é€šè¿‡æµ‹è¯• | {self.test_stats['passed_tests']} âœ… |
| å¤±è´¥æµ‹è¯• | {self.test_stats['failed_tests']} âŒ |
| è·³è¿‡æµ‹è¯• | {self.test_stats.get('skipped_tests', 0)} â­ï¸ |

## ğŸ§ª æµ‹è¯•å¥—ä»¶è¯¦æƒ…

"""
        
        for suite_name, result in self.test_results.items():
            status_icon = "âœ…" if result['passed'] else "âŒ"
            report_content += f"""### {status_icon} {suite_name}

- **çŠ¶æ€**: {'é€šè¿‡' if result['passed'] else 'å¤±è´¥'}
- **æ‰§è¡Œæ—¶é—´**: {result['execution_time']:.2f} ç§’
- **æµ‹è¯•æ•°é‡**: {result['test_count']}
- **é€šè¿‡æ•°é‡**: {result['passed_count']}
- **å¤±è´¥æ•°é‡**: {result['failed_count']}

"""
            
            if result['error']:
                report_content += f"""**é”™è¯¯ä¿¡æ¯**:
```
{result['error'][:500]}{'...' if len(result['error']) > 500 else ''}
```

"""
        
        # æ·»åŠ æ€»ç»“
        if success_rate == 100:
            report_content += """## ğŸ‰ æµ‹è¯•ç»“è®º

**æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼** ç³»ç»Ÿå·²è¾¾åˆ°é›¶å®¹å¿è´¨é‡æ ‡å‡†ï¼Œå¯ä»¥å®‰å…¨éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒã€‚

"""
        elif success_rate >= 90:
            report_content += f"""## âš ï¸ æµ‹è¯•ç»“è®º

**å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡** ({success_rate:.1f}%)ï¼Œä½†ä»æœ‰å°‘é‡å¤±è´¥éœ€è¦ä¿®å¤ã€‚ç³»ç»ŸåŸºæœ¬è¾¾åˆ°è´¨é‡æ ‡å‡†ã€‚

"""
        else:
            report_content += f"""## âŒ æµ‹è¯•ç»“è®º

**æµ‹è¯•å¤±è´¥è¿‡å¤š** ({success_rate:.1f}%)ï¼Œç³»ç»Ÿæœªè¾¾åˆ°è´¨é‡æ ‡å‡†ï¼Œéœ€è¦é‡å¤§ä¿®å¤ã€‚

"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = PROJECT_ROOT / 'COMPREHENSIVE_TEST_REPORT.md'
        report_file.write_text(report_content, encoding='utf-8')
        
        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        json_report = {
            'timestamp': time.time(),
            'execution_time': total_execution_time,
            'success_rate': success_rate,
            'statistics': self.test_stats,
            'test_results': self.test_results
        }
        
        json_file = PROJECT_ROOT / 'test_results.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        logger.info(f"ğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜: {json_file}")
    
    def calculate_overall_success(self) -> bool:
        """è®¡ç®—æ€»ä½“æˆåŠŸçŠ¶æ€"""
        if self.test_stats['total_tests'] == 0:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰§è¡Œä»»ä½•æµ‹è¯•")
            return False
        
        success_rate = (self.test_stats['passed_tests'] / self.test_stats['total_tests']) * 100
        
        logger.info("=" * 60)
        logger.info(f"ğŸ¯ ç»¼åˆæµ‹è¯•å®Œæˆ")
        logger.info(f"ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}% ({self.test_stats['passed_tests']}/{self.test_stats['total_tests']})")
        logger.info(f"â±ï¸ æ€»æ—¶é—´: {time.time() - self.start_time:.2f}ç§’")
        
        if success_rate == 100:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¾¾åˆ°é›¶å®¹å¿è´¨é‡æ ‡å‡†ï¼")
            return True
        elif success_rate >= 90:
            logger.warning(f"âš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œä½†æœ‰{self.test_stats['failed_tests']}ä¸ªå¤±è´¥")
            return False
        else:
            logger.error(f"âŒ æµ‹è¯•å¤±è´¥è¿‡å¤šï¼Œç³»ç»Ÿæœªè¾¾åˆ°è´¨é‡æ ‡å‡†")
            return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨AIDCIS3-LFSç»¼åˆæµ‹è¯•å¥—ä»¶")
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not PROJECT_ROOT.exists():
        logger.error("âŒ é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨")
        return 1
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONPATH'] = str(PROJECT_ROOT)
    os.environ['QT_QPA_PLATFORM'] = 'offscreen'
    
    # è¿è¡Œæµ‹è¯•å¥—ä»¶
    test_suite = ComprehensiveTestSuite()
    success = test_suite.run_all_tests()
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())