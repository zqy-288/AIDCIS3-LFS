"""
ä¼ ç»ŸCSVè¯»å–å™¨ - ç›´æ¥åŸºäºé‡æ„å‰ä»£ç ï¼Œä¸ä¾èµ–å…¶ä»–æ¨¡å—
ä¸“é—¨è§£å†³æ•°æ®è¯»å–ä¸å®Œæ•´çš„é—®é¢˜
"""

import csv
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict


class LegacyCSVReader:
    """
    ä¼ ç»ŸCSVè¯»å–å™¨ - å®Œå…¨å¤åˆ¶é‡æ„å‰çš„read_csv_fileæ–¹æ³•
    ç¡®ä¿èƒ½è¯»å–å®Œæ•´çš„836æ¡æ•°æ®
    """
    
    def __init__(self, data_root_path=None):
        if data_root_path:
            self.data_root_path = Path(data_root_path)
        else:
            # è‡ªåŠ¨æ£€æµ‹æ•°æ®ç›®å½•
            possible_paths = [
                Path("D:\\AIDCIS3-LFS-master\\Data\\CAP1000"),
                Path("/mnt/d/AIDCIS3-LFS-master/Data/CAP1000"),
                Path("D:/AIDCIS3-LFS-master/Data/CAP1000"),
            ]
            
            for path in possible_paths:
                if path.exists():
                    self.data_root_path = path
                    break
            else:
                self.data_root_path = Path("/mnt/d/AIDCIS3-LFS-master/Data/CAP1000")
    
    def load_csv_data_for_hole(self, hole_id):
        """æ ¹æ®å­”IDåŠ è½½å¯¹åº”çš„CSVæ•°æ® - å®Œå…¨åŸºäºé‡æ„å‰é€»è¾‘"""
        # æŸ¥æ‰¾CSVæ–‡ä»¶è·¯å¾„
        csv_paths = [
            self.data_root_path / hole_id / "CCIDM",
            self.data_root_path / hole_id,
        ]

        csv_files = []
        csv_dir = None

        # æŸ¥æ‰¾å­˜åœ¨çš„CSVç›®å½•
        for path in csv_paths:
            if path.exists():
                csv_dir = path
                # æŸ¥æ‰¾CSVæ–‡ä»¶
                for csv_file in path.iterdir():
                    if csv_file.suffix.lower() == '.csv':
                        csv_files.append(csv_file)
                if csv_files:
                    break

        if not csv_files:
            print(f"CSVæ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–æ— CSVæ–‡ä»¶ï¼Œå·²æ£€æŸ¥è·¯å¾„: {csv_paths}")
            return []

        # æŒ‰æ—¶é—´æ’åº
        csv_files.sort()

        # é€‰æ‹©ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶ï¼ˆé€šå¸¸æ¯ä¸ªå­”ä½åªæœ‰ä¸€ä¸ªCSVæ–‡ä»¶ï¼‰
        selected_file = csv_files[0]
        print(f"ä¸ºå­”ID {hole_id} é€‰æ‹©æ–‡ä»¶: {selected_file}")

        # è¯»å–CSVæ–‡ä»¶æ•°æ®
        return self.read_csv_file(selected_file)

    def read_csv_file(self, file_path):
        """è¯»å–CSVæ–‡ä»¶å¹¶è¿”å›æµ‹é‡æ•°æ® - å®Œå…¨å¤åˆ¶é‡æ„å‰é€»è¾‘"""
        measurements = []

        try:
            # å°è¯•ä¸åŒçš„ç¼–ç 
            encodings = ['gbk', 'gb2312', 'utf-8', 'latin-1']

            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as file:
                        reader = csv.reader(file)
                        headers = next(reader)

                        print(f"æˆåŠŸä½¿ç”¨ç¼–ç  {encoding} è¯»å–æ–‡ä»¶")
                        print(f"CSVæ–‡ä»¶åˆ—å¤´: {headers}")

                        # æŸ¥æ‰¾åˆ—ç´¢å¼• - æ ¹æ®å®é™…CSVæ–‡ä»¶ç»“æ„è°ƒæ•´
                        measurement_col = 0  # ç¬¬ä¸€åˆ—æ˜¯æµ‹é‡åºå·
                        channel1_col = 1     # é€šé“1å€¼
                        channel2_col = 2     # é€šé“2å€¼
                        channel3_col = 3     # é€šé“3å€¼
                        diameter_col = 4     # è®¡ç®—ç›´å¾„

                        # éªŒè¯åˆ—æ•°æ˜¯å¦è¶³å¤Ÿ
                        if len(headers) < 5:
                            print(f"CSVæ–‡ä»¶åˆ—æ•°ä¸è¶³: {len(headers)} < 5")
                            continue

                        # è¯»å–æ•°æ®è¡Œ - åœ¨åŒä¸€ä¸ªwithå—ä¸­ï¼Œç¡®ä¿è¯»å–æ‰€æœ‰è¡Œ
                        data_count = 0  # æ·»åŠ è®¡æ•°å™¨è·Ÿè¸ª
                        for row_num, row in enumerate(reader, start=2):
                            try:
                                if len(row) >= 5:  # æ”¹ç”¨>=ç¡®ä¿è‡³å°‘æœ‰5åˆ—
                                    position = float(row[measurement_col])  # æµ‹é‡åºå·å¯¹åº”ä½ç½®(mm)
                                    diameter = float(row[diameter_col])
                                    channel1 = float(row[channel1_col])
                                    channel2 = float(row[channel2_col])
                                    channel3 = float(row[channel3_col])
                                    
                                    data_count += 1  # è®¡æ•°æˆåŠŸè§£æçš„è¡Œ

                                    # åˆ¤æ–­æ˜¯å¦åˆæ ¼ï¼ˆæ ‡å‡†ç›´å¾„17.73mmï¼Œéå¯¹ç§°å…¬å·®+0.07/-0.05mmï¼‰
                                    standard_diameter = 17.73
                                    upper_tolerance = 0.07
                                    lower_tolerance = 0.05
                                    is_qualified = (standard_diameter - lower_tolerance <= diameter <= standard_diameter + upper_tolerance)

                                    # æ¨¡æ‹Ÿæ—¶é—´ï¼ˆåŸºäºæ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼‰
                                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                                    # ä¸ºæ¯ä¸ªæ•°æ®ç‚¹æ·»åŠ ç§’æ•°åç§»ï¼Œæ­£ç¡®å¤„ç†åˆ†é’Ÿè¿›ä½
                                    total_seconds = file_time.second + (row_num - 2)
                                    additional_minutes = total_seconds // 60
                                    new_seconds = total_seconds % 60

                                    # è®¡ç®—æ–°çš„åˆ†é’Ÿæ•°ï¼Œä¹Ÿè¦å¤„ç†å°æ—¶è¿›ä½
                                    total_minutes = file_time.minute + additional_minutes
                                    additional_hours = total_minutes // 60
                                    new_minutes = total_minutes % 60

                                    # è®¡ç®—æ–°çš„å°æ—¶æ•°
                                    new_hours = (file_time.hour + additional_hours) % 24

                                    data_time = file_time.replace(hour=new_hours, minute=new_minutes, second=new_seconds)

                                    measurements.append({
                                        'position': position,
                                        'diameter': diameter,
                                        'channel1': channel1,
                                        'channel2': channel2,
                                        'channel3': channel3,
                                        'is_qualified': is_qualified,
                                        'timestamp': data_time,
                                        'operator': '',  # æš‚ä¸æ˜¾ç¤º
                                        'sequence': row_num - 1,  # åºå·
                                        'depth': position,        # æ·±åº¦ä¸ä½ç½®ç›¸åŒ
                                        'notes': ''               # å¤‡æ³¨
                                    })

                            except (ValueError, IndexError) as e:
                                print(f"è§£æç¬¬{row_num}è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                                continue

                        # æˆåŠŸè¯»å–ï¼Œè·³å‡ºç¼–ç å¾ªç¯
                        print(f"ğŸ“Š å®é™…è§£ææˆåŠŸçš„æ•°æ®è¡Œæ•°: {data_count}")
                        break

                except UnicodeDecodeError:
                    continue
            else:
                print(f"æ— æ³•ä½¿ç”¨ä»»ä½•ç¼–ç è¯»å–æ–‡ä»¶: {file_path}")
                return []

        except Exception as e:
            print(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []

        print(f"æˆåŠŸè¯»å– {len(measurements)} æ¡æµ‹é‡æ•°æ®")
        return measurements