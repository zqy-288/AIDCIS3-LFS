"""
ç»Ÿä¸€IDç®¡ç†å™¨
è´Ÿè´£ç®¡ç†å’Œè½¬æ¢æ‰€æœ‰å­”ä½IDæ ¼å¼ï¼Œç¡®ä¿ç³»ç»Ÿå„æ¨¡å—é—´çš„IDä¸€è‡´æ€§
è§£å†³DXFè§£æã€æ‰‡å½¢åˆ†é…ã€å›¾å½¢æ˜¾ç¤ºç­‰æ¨¡å—é—´çš„IDæ ¼å¼ä¸åŒ¹é…é—®é¢˜
"""

import re
import time
from typing import Dict, List, Tuple, Optional, Set, Any
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict, Counter
from PySide6.QtCore import QObject, Signal

from src.core_business.models.hole_data import HoleData, HoleCollection


class IDFormat(Enum):
    """å­”ä½IDæ ¼å¼ç±»å‹"""
    DXF_ORIGINAL = "dxf_original"          # DXFåŸå§‹æ ¼å¼ï¼ˆå¯èƒ½å„ç§æ ¼å¼ï¼‰
    STANDARD_CRR = "CxxxRyyy"              # æ—§æ ‡å‡†æ ¼å¼ï¼šC001R002
    STANDARD_ACBC = "ACxxxRyyy"            # æ–°æ ‡å‡†æ ¼å¼ï¼šAC001R001, BC001R001
    GRID_POSITION = "row_col"              # ç½‘æ ¼ä½ç½®ï¼š(è¡Œ,åˆ—)
    SEQUENTIAL = "sequential"              # è¿ç»­ç¼–å·ï¼šH001, H002
    CUSTOM = "custom"                      # è‡ªå®šä¹‰æ ¼å¼


@dataclass
class IDPattern:
    """IDæ¨¡å¼å®šä¹‰"""
    format_type: IDFormat
    pattern: str                           # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    template: str                          # æ ¼å¼åŒ–æ¨¡æ¿
    description: str                       # æè¿°
    priority: int = 0                      # ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰


@dataclass
class IDMappingRule:
    """IDæ˜ å°„è§„åˆ™"""
    source_format: IDFormat
    target_format: IDFormat
    converter_func: callable
    description: str


@dataclass 
class IDAnalysisResult:
    """IDåˆ†æç»“æœ"""
    total_count: int
    detected_formats: Dict[IDFormat, int]  # æ ¼å¼ -> æ•°é‡
    primary_format: IDFormat
    confidence: float                      # è¯†åˆ«ç½®ä¿¡åº¦ 0-1
    sample_ids: List[str]                  # æ ·æœ¬ID
    format_details: Dict[IDFormat, Dict]   # è¯¦ç»†åˆ†æç»“æœ


class UnifiedIDManager(QObject):
    """ç»Ÿä¸€IDç®¡ç†å™¨"""
    
    # ä¿¡å·å®šä¹‰
    id_format_detected = Signal(IDFormat, float)  # æ ¼å¼, ç½®ä¿¡åº¦
    id_mapping_completed = Signal(dict)           # æ˜ å°„å®Œæˆ
    id_conflict_detected = Signal(list)          # IDå†²çªæ£€æµ‹
    
    def __init__(self):
        super().__init__()
        
        # IDæ¨¡å¼å®šä¹‰
        self.patterns = self._initialize_patterns()
        
        # æ˜ å°„è§„åˆ™
        self.mapping_rules = self._initialize_mapping_rules()
        
        # IDæ•°æ®å­˜å‚¨
        self.original_ids: List[str] = []                    # åŸå§‹IDåˆ—è¡¨
        self.id_mappings: Dict[str, Dict[IDFormat, str]] = {}  # IDæ˜ å°„è¡¨
        self.reverse_mappings: Dict[IDFormat, Dict[str, str]] = {}  # åå‘æ˜ å°„
        
        # åˆ†æç»“æœ
        self.analysis_result: Optional[IDAnalysisResult] = None
        self.primary_format: IDFormat = IDFormat.STANDARD_CRR
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_ids_processed': 0,
            'mapping_operations': 0,
            'format_conversions': 0,
            'conflicts_resolved': 0
        }
    
    def _initialize_patterns(self) -> Dict[IDFormat, IDPattern]:
        """åˆå§‹åŒ–IDæ¨¡å¼å®šä¹‰"""
        patterns = {
            IDFormat.STANDARD_ACBC: IDPattern(
                format_type=IDFormat.STANDARD_ACBC,
                pattern=r'^([AB])C(\d{3})R(\d{3})$',
                template='{side}C{col:03d}R{row:03d}',
                description='æ–°æ ‡å‡†æ ¼å¼ï¼šAC001R001, BC001R001',
                priority=150
            ),
            
            IDFormat.STANDARD_CRR: IDPattern(
                format_type=IDFormat.STANDARD_CRR,
                pattern=r'^C(\d{3})R(\d{3})$',
                template='C{col:03d}R{row:03d}',
                description='æ—§æ ‡å‡†æ ¼å¼ï¼šC001R002',
                priority=100
            ),
            
            IDFormat.DXF_ORIGINAL: IDPattern(
                format_type=IDFormat.DXF_ORIGINAL,
                pattern=r'^[A-Za-z0-9_\-\.]+$',
                template='{original}',
                description='DXFåŸå§‹æ ¼å¼ï¼ˆå¤šæ ·åŒ–ï¼‰',
                priority=10
            ),
            
            IDFormat.SEQUENTIAL: IDPattern(
                format_type=IDFormat.SEQUENTIAL,
                pattern=r'^H(\d+)$',
                template='H{seq:03d}',
                description='è¿ç»­ç¼–å·ï¼šH001, H002',
                priority=50
            ),
            
            IDFormat.GRID_POSITION: IDPattern(
                format_type=IDFormat.GRID_POSITION,
                pattern=r'^(\d+),(\d+)$',
                template='{row},{col}',
                description='ç½‘æ ¼ä½ç½®ï¼šè¡Œ,åˆ—',
                priority=30
            ),
        }
        
        return patterns
    
    def _initialize_mapping_rules(self) -> List[IDMappingRule]:
        """åˆå§‹åŒ–IDæ˜ å°„è§„åˆ™"""
        rules = [
            # DXFåŸå§‹ -> æ ‡å‡†æ ¼å¼
            IDMappingRule(
                source_format=IDFormat.DXF_ORIGINAL,
                target_format=IDFormat.STANDARD_CRR,
                converter_func=self._convert_dxf_to_standard,
                description='DXFåŸå§‹æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†CxxxRyyyæ ¼å¼'
            ),
            
            # ç½‘æ ¼ä½ç½® -> æ ‡å‡†æ ¼å¼
            IDMappingRule(
                source_format=IDFormat.GRID_POSITION,
                target_format=IDFormat.STANDARD_CRR,
                converter_func=self._convert_grid_to_standard,
                description='ç½‘æ ¼ä½ç½®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼'
            ),
            
            # è¿ç»­ç¼–å· -> æ ‡å‡†æ ¼å¼
            IDMappingRule(
                source_format=IDFormat.SEQUENTIAL,
                target_format=IDFormat.STANDARD_CRR,
                converter_func=self._convert_sequential_to_standard,
                description='è¿ç»­ç¼–å·è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼'
            ),
        ]
        
        return rules
    
    def analyze_hole_collection(self, hole_collection: HoleCollection) -> IDAnalysisResult:
        """
        åˆ†æå­”ä½é›†åˆçš„IDæ ¼å¼
        
        Args:
            hole_collection: å­”ä½é›†åˆ
            
        Returns:
            IDAnalysisResult: åˆ†æç»“æœ
        """
        print(f"ğŸ” [IDç®¡ç†å™¨] å¼€å§‹åˆ†æå­”ä½IDæ ¼å¼...")
        
        start_time = time.perf_counter()
        
        self.original_ids = list(hole_collection.holes.keys())
        total_count = len(self.original_ids)
        
        # æ£€æµ‹å„ç§æ ¼å¼
        format_counts = defaultdict(int)
        format_samples = defaultdict(list)
        
        for hole_id in self.original_ids:
            detected_formats = self._detect_id_format(hole_id)
            
            for format_type in detected_formats:
                format_counts[format_type] += 1
                if len(format_samples[format_type]) < 5:
                    format_samples[format_type].append(hole_id)
        
        # ç¡®å®šä¸»è¦æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§å’Œæ•°é‡ï¼‰
        primary_format = self._determine_primary_format(format_counts)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        primary_count = format_counts.get(primary_format, 0)
        confidence = primary_count / total_count if total_count > 0 else 0.0
        
        # ç”Ÿæˆåˆ†æç»“æœ
        self.analysis_result = IDAnalysisResult(
            total_count=total_count,
            detected_formats=dict(format_counts),
            primary_format=primary_format,
            confidence=confidence,
            sample_ids=format_samples[primary_format][:5],
            format_details={
                fmt: {
                    'count': count,
                    'percentage': (count / total_count * 100) if total_count > 0 else 0,
                    'samples': format_samples[fmt][:3]
                }
                for fmt, count in format_counts.items()
            }
        )
        
        elapsed_time = time.perf_counter() - start_time
        
        print(f"ğŸ“Š [IDç®¡ç†å™¨] åˆ†æå®Œæˆ:")
        print(f"   æ€»IDæ•°é‡: {total_count}")
        print(f"   ä¸»è¦æ ¼å¼: {primary_format.value} (ç½®ä¿¡åº¦: {confidence:.2%})")
        print(f"   æ£€æµ‹åˆ°çš„æ ¼å¼:")
        
        for fmt, details in self.analysis_result.format_details.items():
            print(f"     {fmt.value}: {details['count']} ({details['percentage']:.1f}%) - æ ·æœ¬: {details['samples']}")
        
        print(f"   åˆ†æè€—æ—¶: {elapsed_time:.3f}ç§’")
        
        # å‘å°„ä¿¡å·
        self.id_format_detected.emit(primary_format, confidence)
        
        return self.analysis_result
    
    def _detect_id_format(self, hole_id: str) -> List[IDFormat]:
        """æ£€æµ‹å•ä¸ªIDçš„å¯èƒ½æ ¼å¼"""
        detected = []
        
        for format_type, pattern in self.patterns.items():
            if re.match(pattern.pattern, hole_id):
                detected.append(format_type)
        
        return detected
    
    def _determine_primary_format(self, format_counts: Dict[IDFormat, int]) -> IDFormat:
        """æ ¹æ®ä¼˜å…ˆçº§å’Œæ•°é‡ç¡®å®šä¸»è¦æ ¼å¼"""
        if not format_counts:
            return IDFormat.STANDARD_CRR
        
        # æŒ‰ä¼˜å…ˆçº§*æ•°é‡æ’åº
        scored_formats = []
        for format_type, count in format_counts.items():
            priority = self.patterns[format_type].priority
            score = priority * count
            scored_formats.append((score, format_type))
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„æ ¼å¼
        scored_formats.sort(reverse=True)
        return scored_formats[0][1]
    
    def create_unified_mappings(self, hole_collection: HoleCollection, target_format: IDFormat = IDFormat.STANDARD_CRR) -> Dict[str, str]:
        """
        åˆ›å»ºç»Ÿä¸€çš„IDæ˜ å°„
        
        Args:
            hole_collection: å­”ä½é›†åˆ
            target_format: ç›®æ ‡æ ¼å¼
            
        Returns:
            Dict[str, str]: åŸå§‹ID -> ç»Ÿä¸€IDçš„æ˜ å°„è¡¨
        """
        print(f"ğŸ”„ [IDç®¡ç†å™¨] åˆ›å»ºç»Ÿä¸€IDæ˜ å°„ï¼Œç›®æ ‡æ ¼å¼: {target_format.value}")
        
        start_time = time.perf_counter()
        
        # ç¡®ä¿å·²åˆ†æ
        if not self.analysis_result:
            self.analyze_hole_collection(hole_collection)
        
        unified_mappings = {}
        self.id_mappings.clear()
        self.reverse_mappings.clear()
        
        # ä¸ºæ¯ä¸ªæ ¼å¼åˆå§‹åŒ–åå‘æ˜ å°„
        for fmt in IDFormat:
            self.reverse_mappings[fmt] = {}
        
        conflicts = []
        conversion_count = 0
        
        for original_id, hole_data in hole_collection.holes.items():
            try:
                # æ£€æµ‹åŸå§‹IDæ ¼å¼
                detected_formats = self._detect_id_format(original_id)
                
                if not detected_formats:
                    print(f"âš ï¸ [IDç®¡ç†å™¨] æ— æ³•è¯†åˆ«IDæ ¼å¼: {original_id}")
                    unified_id = original_id  # ä¿æŒåŸæ ·
                else:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„æ ¼å¼è¿›è¡Œè½¬æ¢
                    source_format = detected_formats[0]
                    unified_id = self._convert_id(original_id, source_format, target_format, hole_data)
                    conversion_count += 1
                
                # æ£€æŸ¥å†²çª
                if unified_id in self.reverse_mappings[target_format]:
                    existing_original = self.reverse_mappings[target_format][unified_id]
                    conflicts.append({
                        'unified_id': unified_id,
                        'original_ids': [existing_original, original_id],
                        'resolved_id': f"{unified_id}_DUP{len(conflicts)+1}"
                    })
                    unified_id = conflicts[-1]['resolved_id']
                
                # å­˜å‚¨æ˜ å°„
                unified_mappings[original_id] = unified_id
                
                # åˆ›å»ºå®Œæ•´çš„æ˜ å°„è®°å½•
                self.id_mappings[original_id] = {target_format: unified_id}
                self.reverse_mappings[target_format][unified_id] = original_id
                
            except Exception as e:
                print(f"âŒ [IDç®¡ç†å™¨] è½¬æ¢IDå¤±è´¥ {original_id}: {e}")
                unified_mappings[original_id] = original_id
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_ids_processed'] = len(unified_mappings)
        self.stats['format_conversions'] = conversion_count
        self.stats['conflicts_resolved'] = len(conflicts)
        self.stats['mapping_operations'] += 1
        
        elapsed_time = time.perf_counter() - start_time
        
        print(f"âœ… [IDç®¡ç†å™¨] ç»Ÿä¸€æ˜ å°„åˆ›å»ºå®Œæˆ:")
        print(f"   å¤„ç†IDæ•°é‡: {len(unified_mappings)}")
        print(f"   æ ¼å¼è½¬æ¢æ•°: {conversion_count}")
        print(f"   å†²çªè§£å†³æ•°: {len(conflicts)}")
        print(f"   åˆ›å»ºè€—æ—¶: {elapsed_time:.3f}ç§’")
        
        if conflicts:
            print(f"ğŸ”§ [IDç®¡ç†å™¨] è§£å†³çš„IDå†²çª:")
            for conflict in conflicts[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"     {conflict['original_ids']} â†’ {conflict['resolved_id']}")
            if len(conflicts) > 3:
                print(f"     ... è¿˜æœ‰{len(conflicts)-3}ä¸ªå†²çª")
        
        # å‘å°„ä¿¡å·
        self.id_conflict_detected.emit(conflicts)
        self.id_mapping_completed.emit({
            'total_mapped': len(unified_mappings),
            'conversions': conversion_count,
            'conflicts': len(conflicts),
            'target_format': target_format.value
        })
        
        return unified_mappings
    
    def _convert_id(self, original_id: str, source_format: IDFormat, target_format: IDFormat, hole_data: HoleData) -> str:
        """è½¬æ¢å•ä¸ªID"""
        if source_format == target_format:
            return original_id
        
        # æŸ¥æ‰¾é€‚ç”¨çš„æ˜ å°„è§„åˆ™
        for rule in self.mapping_rules:
            if rule.source_format == source_format and rule.target_format == target_format:
                return rule.converter_func(original_id, hole_data)
        
        # å¦‚æœæ²¡æœ‰ç›´æ¥è§„åˆ™ï¼Œå°è¯•é€šç”¨è½¬æ¢
        return self._generic_id_conversion(original_id, source_format, target_format, hole_data)
    
    def _convert_dxf_to_standard(self, original_id: str, hole_data: HoleData) -> str:
        """DXFåŸå§‹æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if re.match(r'^C(\d{3})R(\d{3})$', original_id):
            return original_id
        
        # ä½¿ç”¨å­”ä½çš„è¡Œåˆ—ä¿¡æ¯
        if hole_data.row is not None and hole_data.column is not None:
            return f"C{hole_data.column:03d}R{hole_data.row:03d}"
        
        # å°è¯•ä»IDä¸­æå–æ•°å­—
        numbers = re.findall(r'\d+', original_id)
        if len(numbers) >= 2:
            col, row = int(numbers[0]), int(numbers[1])
            return f"C{col:03d}R{row:03d}"
        elif len(numbers) == 1:
            # å•ä¸ªæ•°å­—ï¼Œå‡è®¾ä¸ºåºå·
            seq = int(numbers[0])
            # ç®€å•çš„åºå·åˆ°è¡Œåˆ—è½¬æ¢ï¼ˆå‡è®¾100åˆ—ï¼‰
            row = seq // 100 + 1
            col = seq % 100 + 1
            return f"C{col:03d}R{row:03d}"
        
        # æ— æ³•è½¬æ¢ï¼Œç”Ÿæˆå”¯ä¸€ID
        return f"C999R{hash(original_id) % 1000:03d}"
    
    def _convert_grid_to_standard(self, original_id: str, hole_data: HoleData) -> str:
        """ç½‘æ ¼ä½ç½®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        match = re.match(r'^(\d+),(\d+)$', original_id)
        if match:
            row, col = int(match.group(1)), int(match.group(2))
            return f"C{col:03d}R{row:03d}"
        return original_id
    
    def _convert_sequential_to_standard(self, original_id: str, hole_data: HoleData) -> str:
        """è¿ç»­ç¼–å·è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        match = re.match(r'^H(\d+)$', original_id)
        if match:
            seq = int(match.group(1))
            # ç®€å•çš„åºå·åˆ°è¡Œåˆ—è½¬æ¢ï¼ˆå‡è®¾100åˆ—ï¼‰
            row = seq // 100 + 1
            col = seq % 100 + 1
            return f"C{col:03d}R{row:03d}"
        return original_id
    
    def _generic_id_conversion(self, original_id: str, source_format: IDFormat, target_format: IDFormat, hole_data: HoleData) -> str:
        """é€šç”¨IDè½¬æ¢æ–¹æ³•"""
        if target_format == IDFormat.STANDARD_CRR:
            return self._convert_dxf_to_standard(original_id, hole_data)
        elif target_format == IDFormat.SEQUENTIAL:
            # è½¬æ¢ä¸ºè¿ç»­ç¼–å·
            numbers = re.findall(r'\d+', original_id)
            if numbers:
                return f"H{int(numbers[0]):03d}"
            return f"H{hash(original_id) % 1000:03d}"
        else:
            return original_id
    
    def get_unified_id(self, original_id: str, target_format: IDFormat = IDFormat.STANDARD_CRR) -> Optional[str]:
        """è·å–ç»Ÿä¸€ID"""
        mapping = self.id_mappings.get(original_id, {})
        return mapping.get(target_format)
    
    def get_original_id(self, unified_id: str, source_format: IDFormat = IDFormat.STANDARD_CRR) -> Optional[str]:
        """æ ¹æ®ç»Ÿä¸€IDè·å–åŸå§‹ID"""
        reverse_map = self.reverse_mappings.get(source_format, {})
        return reverse_map.get(unified_id)
    
    def get_format_statistics(self) -> Dict[str, Any]:
        """è·å–æ ¼å¼ç»Ÿè®¡ä¿¡æ¯"""
        if not self.analysis_result:
            return {}
        
        return {
            'analysis_result': {
                'total_count': self.analysis_result.total_count,
                'primary_format': self.analysis_result.primary_format.value,
                'confidence': self.analysis_result.confidence,
                'format_distribution': {
                    fmt.value: details for fmt, details in self.analysis_result.format_details.items()
                }
            },
            'mapping_stats': self.stats.copy(),
            'current_mappings': len(self.id_mappings)
        }
    
    def validate_mappings(self) -> Dict[str, Any]:
        """éªŒè¯æ˜ å°„çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§"""
        print(f"ğŸ” [IDç®¡ç†å™¨] éªŒè¯æ˜ å°„å®Œæ•´æ€§...")
        
        issues = []
        stats = {
            'total_mappings': len(self.id_mappings),
            'missing_mappings': 0,
            'invalid_formats': 0,
            'duplicate_targets': 0
        }
        
        # æ£€æŸ¥é‡å¤çš„ç›®æ ‡ID
        target_counts = defaultdict(int)
        for original_id, mappings in self.id_mappings.items():
            for target_format, target_id in mappings.items():
                target_counts[(target_format, target_id)] += 1
        
        duplicates = {k: count for k, count in target_counts.items() if count > 1}
        if duplicates:
            stats['duplicate_targets'] = len(duplicates)
            issues.extend([f"é‡å¤ç›®æ ‡ID: {target_id} ({fmt.value}) - {count}æ¬¡" 
                          for (fmt, target_id), count in list(duplicates.items())[:5]])
        
        print(f"âœ… [IDç®¡ç†å™¨] æ˜ å°„éªŒè¯å®Œæˆ:")
        print(f"   æ€»æ˜ å°„æ•°: {stats['total_mappings']}")
        print(f"   é‡å¤ç›®æ ‡: {stats['duplicate_targets']}")
        if issues:
            print(f"   å‘ç°é—®é¢˜: {len(issues)} ä¸ª")
            for issue in issues[:3]:
                print(f"     - {issue}")
        
        return {
            'stats': stats,
            'issues': issues,
            'is_valid': len(issues) == 0
        }
    
    def export_mapping_table(self, target_format: IDFormat = IDFormat.STANDARD_CRR) -> Dict[str, str]:
        """å¯¼å‡ºæ˜ å°„è¡¨"""
        mapping_table = {}
        for original_id, mappings in self.id_mappings.items():
            unified_id = mappings.get(target_format)
            if unified_id:
                mapping_table[original_id] = unified_id
        
        print(f"ğŸ“¤ [IDç®¡ç†å™¨] å¯¼å‡ºæ˜ å°„è¡¨: {len(mapping_table)} æ¡è®°å½•")
        return mapping_table
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        self.original_ids.clear()
        self.id_mappings.clear()
        self.reverse_mappings.clear()
        self.analysis_result = None
        self.stats = {
            'total_ids_processed': 0,
            'mapping_operations': 0,
            'format_conversions': 0,
            'conflicts_resolved': 0
        }
        print(f"ğŸ§¹ [IDç®¡ç†å™¨] æ•°æ®æ¸…ç†å®Œæˆ")